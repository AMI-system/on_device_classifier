{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data counts (image counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "\n",
    "def data_statistics(data_directory):\n",
    "    \"\"\"main function for updating the data statistics file in the root moths folder\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame([], columns=[\"Family\",\"Genus\",\"Species\",\"N\"])\n",
    "    family_dirs = next(os.walk(data_directory))[1]\n",
    "    \n",
    "    for f in family_dirs:\n",
    "        genus_dirs = next(os.walk(data_directory + f))[1]\n",
    "        for g in genus_dirs:\n",
    "            species_dirs = next(os.walk(data_directory + f + '/' + g))[1]\n",
    "            for s in species_dirs:\n",
    "                images = os.listdir(data_directory + f + '/' + g + '/' + s)\n",
    "                images = [k for k in images if 'jpg' in k]\n",
    "                n = len(images)\n",
    "                data = [f, g, s, n]\n",
    "                data = pd.DataFrame(data).transpose()\n",
    "                data.columns = [\"Family\",\"Genus\",\"Species\",\"N\"]\n",
    "                df = pd.concat([df, data], ignore_index=True)\n",
    "    return df\n",
    "        \n",
    "    # print(family_dirs)\n",
    "\n",
    "df1 = data_statistics('/bask/homes/f/fspo1218/amber/data/gbif_macro_data/gbif_macro/')\n",
    "df2 = data_statistics('/bask/homes/f/fspo1218/amber/data/binary_moth_training/gbif_crops/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/bask/homes/f/fspo1218/amber/data/gbif_macro_data/gbif_macro/data_statistics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogram of the counts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "ax[0].hist(df1['N'], bins=20)\n",
    "ax[0].set_title('Counts of species images downloaded (All GBIF, 990 species total)')\n",
    "ax[0].set_xlabel('Number of images collected')\n",
    "ax[0].set_ylabel('Counts')\n",
    "\n",
    "\n",
    "ax[1].hist(df2['N'], bins=20)\n",
    "ax[1].set_title('Counts of species images downloaded (Megadetector cropped, 990 species total)')\n",
    "ax[1].set_xlabel('Number of images collected')\n",
    "ax[1].set_ylabel('Counts')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('/bask/projects/v/vjgo8416-amber/data/gbif-species-trainer-AMI-fork/gbif_images/try_wrapper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/bask/projects/v/vjgo8416-amber/data/gbif-species-trainer-AMI-fork/gbif_images/try_wrapper/data_statistics.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogram of the counts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "ax[0].hist(df['image_count'], bins=20)\n",
    "ax[0].set_title('Counts of species images downloaded (' + str(df.shape[0]) + ' species total)')\n",
    "ax[0].set_xlabel('Number of images collected')\n",
    "ax[0].set_ylabel('Counts')\n",
    "\n",
    "\n",
    "ax[1].hist(df.loc[df['image_count'] < 100, 'image_count'], bins=20)\n",
    "ax[1].set_title('Counts of species images downloaded (where number < 100)')\n",
    "ax[1].set_xlabel('Number of images collected')\n",
    "ax[1].set_ylabel('Counts')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/bask/projects/v/vjgo8416-amber/projects/on_device_classifier/model_training/updated_myfile.csv', on_bad_lines='skip')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = df['True_label'] == df['MILA_prediction']\n",
    "# image_species = list(set(df['True_label']))\n",
    "# mila_species = list(set(df['MILA_prediction']))\n",
    "\n",
    "import json\n",
    "\n",
    "f = open(\"/bask/homes/f/fspo1218/amber/data/mila_models/01-moths-ukdenmark_v2_category_map_species_names(1).json\")\n",
    "label_info = json.load(f)\n",
    "species_list_mila = list(label_info)\n",
    "print(len(species_list_mila), \" species in total\")\n",
    "\n",
    "f = open(\"/bask/homes/f/fspo1218/amber/data/binary_moth_training/gbif_crop_ready/01_uk_macro_data_numeric_labels.json\")\n",
    "label_info = json.load(f)\n",
    "species_list = label_info[\"species_list\"]\n",
    "print(len(species_list), \" species in total\")\n",
    "\n",
    "\n",
    "common = [value for value in species_list_mila if value in species_list]\n",
    "print(len(common), \"species common to both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "acc_type = [\"Top 10\", \"Top 3\", \"Top 1\"]\n",
    "accuracies = {\n",
    "    'TF Lite': (sum(df['TFLite_top10'])/df.shape[0] * 100, sum(df['TFLite_top3'])/df.shape[0] * 100, sum(df['TFLite_top1'])/df.shape[0] * 100),\n",
    "    'Pytorch': (sum(df['Pytorch_top10'])/df.shape[0] * 100, sum(df['Pytorch_top3'])/df.shape[0] * 100, sum(df['Pytorch_top1'])/df.shape[0] * 100),\n",
    "    'MILA': (sum(df['MILA_top10'])/df.shape[0] * 100, sum(df['MILA_top3'])/df.shape[0] * 100, sum(df['MILA_top1'])/df.shape[0] * 100),\n",
    "}\n",
    "\n",
    "x = np.arange(len(acc_type))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots()#layout='constrained')\n",
    "\n",
    "for attribute, measurement in accuracies.items():\n",
    "    print_meas = [round(x, 2) for x in measurement]\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, print_meas, width, label=attribute)\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "ax.set_ylabel('Percentage of Cases')\n",
    "ax.set_xlabel('Type')\n",
    "ax.set_title('Number of cases where the top X predicted species contains the Truth')\n",
    "ax.set_xticks([x + 0.125 for x in list(range(0, len(acc_type)))])\n",
    "ax.set_xticklabels(acc_type)\n",
    "ax.legend()#loc='upper left', ncols=3)\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(true_col, pred_col):\n",
    "    temp = [1 if df[true_col][i] == df[pred_col][i] else 0 for i in range(df.shape[0])] \n",
    "    temp = sum(temp)/df.shape[0] * 100\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_type = (\"Species\", \"Genus\", \"Family\")\n",
    "\n",
    "accuracies = {\n",
    "    'TF Lite': (calc_acc('True_label', 'TFLite_prediction'), calc_acc('True_genus', 'TFLite_genus'), calc_acc('True_family', 'TFLite_family')),\n",
    "    'Pytorch': (calc_acc('True_label', 'Pytorch_prediction'), calc_acc('True_genus', 'Pytorch_genus'), calc_acc('True_family', 'Pytorch_family')),\n",
    "}\n",
    "\n",
    "x = np.arange(len(acc_type))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots()#layout='constrained')\n",
    "\n",
    "for attribute, measurement in accuracies.items():\n",
    "    print_meas = [round(x, 2) for x in measurement]\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, print_meas, width, label=attribute)\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "ax.set_ylabel('Percentage of Cases')\n",
    "ax.set_xlabel('Taxonomic Level')\n",
    "ax.set_title('Truth = Top 1 at Taxonomic Levels')\n",
    "ax.set_xticks([x + 0.125 for x in list(range(0, len(acc_type)))])\n",
    "ax.set_xticklabels(acc_type)\n",
    "ax.legend()#loc='upper left', ncols=3)\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['True_label_index'] == 0, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.crosstab(df[\"TFLite_prediction\"], df[\"True_label\"], dropna=True, normalize=\"index\")\n",
    "df3 = df3.fillna(0)\n",
    "\n",
    "\n",
    "# Force the df to be square\n",
    "i = list(set(list(df[\"TFLite_prediction\"]) + list(df[\"True_label\"])))\n",
    "df3 = df3.reindex(index=i, columns=i, fill_value=0)\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "fam_dict = pd.Series(list(df.True_family) + list(df.True_family), index=list(df.True_label)+list(df.TFLite_prediction)).to_dict()\n",
    "gen_dict = pd.Series(list(df.True_genus) + list(df.True_genus),index=list(df.True_label)+list(df.TFLite_prediction)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_col = sns.color_palette(\"husl\", len(set(fam_dict.values())))\n",
    "gen_col = sns.color_palette(\"husl\", len(set(gen_dict.values())))\n",
    "\n",
    "fam_col = dict(zip(list(set(fam_dict.values())), [tuple(int(c*255) for c in cs) for cs in fam_col]))\n",
    "gen_col = dict(zip(list(set(gen_dict.values())), [tuple(int(c*255) for c in cs) for cs in gen_col]))\n",
    "\n",
    "# #colors = [tuple(t / 255 for t in x) for x in rgb]\n",
    "\n",
    "# fam_col = [fam_col[fam_dict[x]] for x in list(df3.columns)]\n",
    "# gen_col = [gen_col[gen_dict[x]] for x in list(df3.columns)]\n",
    "\n",
    "# fam_col = [tuple(round(t / 255, 2) for t in x) for x in fam_col]\n",
    "# gen_col = [tuple(round(t / 255, 2) for t in x) for x in gen_col]\n",
    "\n",
    "# len(fam_col)\n",
    "fam_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lut = {'group_1': 'red', 'group_2': 'blue', 'group_3': 'green'}\n",
    "row_colors = pd.DataFrame([fam_dict[x] for x in list(df3.columns)]).map(fam_col)\n",
    "row_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, color in enumerate(row_colors):\n",
    "    ax.add_patch(plt.Rectangle(xy=(-0.05, i), width=0.05, height=1, color=color, lw=0,\n",
    "                               transform=ax.get_yaxis_transform(), clip_on=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "import matplotlib\n",
    "\n",
    "link = linkage(df3.transpose()) \n",
    "\n",
    "genus_colors = pd.DataFrame(data={'genus': gen_col }) \n",
    "family_colors = pd.DataFrame(data={'family': fam_col }) \n",
    "\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "sns.clustermap(df3, row_linkage=link, col_linkage=link, cmap=sns.cm.rocket_r,\n",
    "               row_colors=genus_colors, col_colors=family_colors, \n",
    "               norm=matplotlib.colors.LogNorm(), figsize=(20,15))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genus heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.crosstab(df[\"TFLite_genus\"], df[\"True_genus\"], dropna=True, normalize=\"index\")\n",
    "df4 = df4.fillna(0)\n",
    "\n",
    "\n",
    "# Force the df to be square\n",
    "i = list(set(list(df[\"TFLite_genus\"]) + list(df[\"True_genus\"])))\n",
    "df4 = df4.reindex(index=i, columns=i, fill_value=0)\n",
    "\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "import matplotlib\n",
    "\n",
    "link = linkage(df4.transpose()) \n",
    "\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "sns.clustermap(df4, row_linkage=link, col_linkage=link, cmap=sns.cm.rocket_r,\n",
    "               norm=matplotlib.colors.LogNorm(), figsize=(20,15))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Family Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.crosstab(df[\"TFLite_family\"], df[\"True_family\"], dropna=True, normalize=\"index\")\n",
    "df5 = df5.fillna(0)\n",
    "df5 = df5.div(df5.sum(axis=0), axis=1) # normalise to 1\n",
    "\n",
    "# Force the df to be square\n",
    "i = list(set(list(df[\"TFLite_family\"]) + list(df[\"True_family\"])))\n",
    "df5 = df5.reindex(index=i, columns=i, fill_value=0)\n",
    "\n",
    "link = linkage(df5.transpose()) \n",
    "\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "sns.clustermap(df5, row_linkage=link, col_linkage=link, cmap=sns.cm.rocket_r,\n",
    "               norm=matplotlib.colors.LogNorm(), figsize=(7,7))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.crosstab(df[\"Pytorch_family\"], df[\"True_family\"], dropna=True, normalize=\"index\")\n",
    "df5 = df5.fillna(0)\n",
    "df5 = df5.div(df5.sum(axis=0), axis=1) # normalise to 1\n",
    "\n",
    "# Force the df to be square\n",
    "i = list(set(list(df[\"Pytorch_family\"]) + list(df[\"True_family\"])))\n",
    "df5 = df5.reindex(index=i, columns=i, fill_value=0)\n",
    "\n",
    "link = linkage(df5.transpose()) \n",
    "\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "sns.clustermap(df5, row_linkage=link, col_linkage=link, cmap=sns.cm.rocket_r,\n",
    "               norm=matplotlib.colors.LogNorm(), figsize=(7,7))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_conda_env2 (Conda)",
   "language": "python",
   "name": "sys_kg_conda_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
