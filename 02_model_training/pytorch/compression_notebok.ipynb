{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run and test this you will need to: \n",
    "\n",
    "- source the species_classifier kernel\n",
    "- download the following files: \n",
    "    - `01_uk_macro_data_numeric_labels.json`: for labeling the data\n",
    "    - `turing-macro_v01_efficientnetv2-b3_*.pt`: the model files\n",
    "    - `test-500-{000000..0000*}.tar` : the test data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import json\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import onnx\n",
    "from typing import Literal\n",
    "from typing_extensions import Literal\n",
    "import matplotlib.pyplot as plt\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "from data2 import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the pytorch model\n",
    "model_py = torch.load(\"./outputs/turing-macro_v01_efficientnetv2-b3_2023-06-27-10-45.pt\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test data\n",
    "test_dataloader = dataloader.build_webdataset_pipeline(\n",
    "        sharedurl=\"./outputs/test-500-{000000..000013}.tar\",\n",
    "        input_size=1000,\n",
    "        batch_size=64,\n",
    "        is_training=False,\n",
    "        num_workers=4,\n",
    "        preprocess_mode=\"tf\",\n",
    "    )\n",
    "print(\"images loaded\")\n",
    "\n",
    "image_dummy, label_dummy = next(iter(test_dataloader))\n",
    "image_batch = image_dummy.to(\"cpu\", non_blocking=True)\n",
    "label_batch = label_dummy.to(\"cpu\", non_blocking=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label_batch[0]\n",
    "image = image_batch[0]\n",
    "print(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label info for the species names\n",
    "f = open(\"./outputs/01_uk_macro_data_numeric_labels.json\")\n",
    "label_info = json.load(f)\n",
    "species_list = label_info[\"species_list\"]\n",
    "print(len(species_list), \" species in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to onnx\n",
    "torch.onnx.export(\n",
    "            model=model_py.eval(),\n",
    "            args=image.unsqueeze(0),\n",
    "            f=\"./outputs/onnx_file.onnx\",\n",
    "            verbose=False,\n",
    "            export_params=True,\n",
    "            do_constant_folding=False,\n",
    "            input_names=['input'],\n",
    "            opset_version=12,\n",
    "            output_names=['output']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tf\n",
    "onnx_model = onnx.load(\"./outputs/onnx_file.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "tf_rep = prepare(onnx_model, device='CPU')\n",
    "tf_rep.export_graph(\"./outputs/tf_file\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a working tensorflow model. Lets test one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(image_index, ax):\n",
    "    image = image_batch[image_index]\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    label = label_batch[image_index]\n",
    "\n",
    "    output = tf_rep.run(image)\n",
    "\n",
    "    true_str = \"True: \" + species_list[int(label)]\n",
    "    pred_str = \"Pred: \" + species_list[np.argmax(output)]\n",
    "    text = \"Image \" + str(image_index)\n",
    "\n",
    "    ax.imshow(image_batch[image_index].permute(1, 2, 0))\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, \n",
    "                top=False, left=False, right=False, \n",
    "                labelbottom=False, labelleft=False) \n",
    "\n",
    "    # add annotation label to the plot\n",
    "    ax.annotate(text, (50, 50), color='white')\n",
    "    ax.annotate(true_str, (50, 850), color='white')\n",
    "    ax.annotate(pred_str, (50, 900), color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib subplots 3x3\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "plot_predictions(10, axs[0, 0])\n",
    "plot_predictions(11, axs[0, 1])\n",
    "plot_predictions(12, axs[0, 2])\n",
    "plot_predictions(13, axs[1, 0])\n",
    "plot_predictions(14, axs[1, 1])\n",
    "plot_predictions(15, axs[1, 2])\n",
    "plot_predictions(16, axs[2, 0])\n",
    "plot_predictions(17, axs[2, 1])\n",
    "plot_predictions(18, axs[2, 2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets convert this to s TF Lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tfLite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./outputs/tf_file\")\n",
    "converter.experimental_new_converter = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.allow_custom_ops=True\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./outputs/compressed_model.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing \n",
    "\n",
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"gbif\",\n",
    "    entity=\"kg-test\", \n",
    "    tags=\"tflite\"\n",
    ")\n",
    "\n",
    "wandb.init(settings=wandb.Settings(start_method=\"fork\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.lite.Interpreter(model_path=\"./outputs/compressed_model.tflite\")\n",
    "model.allocate_tensors()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the species label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"./outputs/compressed_model.tflite\")\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "print(\"tflite model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['True_label', 'Pytorch_prediction', 'TF_prediction', 'TFLite_prediction']\n",
    "\n",
    "f = open('myfile.csv', 'w', newline=\"\")\n",
    "\n",
    "# create the csv writer\n",
    "writer = csv.writer(f, delimiter=';')\n",
    "writer.writerow(headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš¨ðŸš¨ warning: the next cell will take a while to run ðŸš¨ðŸš¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in test_dataloader:\n",
    "\n",
    "\n",
    "    image_batch, label_batch = image_batch.to(\n",
    "        device, non_blocking=True\n",
    "    ), label_batch.to(device, non_blocking=True)\n",
    "    \n",
    "    for i in range(len(image_batch)):\n",
    "        s_time = time.time()\n",
    "        image = image_batch[i]\n",
    "\n",
    "\n",
    "        # For pytorch model\n",
    "        outputs_py = model_py(image.unsqueeze(0))\n",
    "        prediction_py = int(torch.max(outputs_py.data, 1)[1].numpy())\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], image.unsqueeze(0))\n",
    "        interpreter.invoke()\n",
    "        outputs_tf = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        prediction_tf = np.squeeze(outputs_tf)\n",
    "        prediction_tf = int(prediction_tf.argsort()[-1:][::-1])\n",
    "        \n",
    "        true_label = int(label_batch[i].numpy())\n",
    "        print(\"true: \", true_label, species_list[true_label], \", \"\n",
    "            \", py: \", prediction_py, species_list[prediction_py], \", \"\n",
    "            \", tf: \", prediction_tf, species_list[prediction_tf])\n",
    "        line = [str(int(true_label)), str(prediction_py), str(prediction_tf)]\n",
    "        writer.writerow(line)\n",
    "        \n",
    "        wandb.log(\n",
    "            {\"training loss\": 0, \"validation loss\": 0, \"epoch\": i}\n",
    "        )\n",
    "        \n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train_micro_species_top1\": 100,\n",
    "                \"train_micro_genus_top1\": 100,\n",
    "                \"train_micro_family_top1\": 100,\n",
    "                \"val_micro_species_top1\": 100,\n",
    "                \"val_micro_genus_top1\": 100,\n",
    "                \"val_micro_family_top1\": 100,\n",
    "                \"epoch\": i,\n",
    "            }\n",
    "        )\n",
    "        e_time = (time.time() - s_time) / 60  # time taken in minutes\n",
    "        wandb.log({\"time per epoch\": e_time, \"epoch\": i})\n",
    "\n",
    "wandb.log_artifact(\"~/Desktop/wandblog\", name=mod_name, type=\"models\")\n",
    "\n",
    "wandb.log({\"final micro accuracy\": 100})\n",
    "wandb.log({\"final macro accuracy\": 100})\n",
    "wandb.log({\"configuration\": \"\"})\n",
    "wandb.log({\"tax accuracy\": 100})\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
