{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run and test this you will need to: \n",
    "\n",
    "- source the species_classifier kernel\n",
    "- download the following files: \n",
    "    - `01_uk_macro_data_numeric_labels.json`: for labeling the data\n",
    "    - `turing-macro_v01_efficientnetv2-b3_*.pt`: the model files\n",
    "    - `test-500-{000000..0000*}.tar` : the test data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from torchvision) (2.27.1)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: jinja2 in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Requirement already satisfied: filelock in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.6.0)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (4.2.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (62.1.0)\n",
      "Requirement already satisfied: wheel in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (0.37.1)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.27.0-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-16.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.7/153.7 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93584 sha256=2e7291c4501dd5ea6017f302285086689e6eef9f12f32027ea73c8f5c2fa0478\n",
      "  Stored in directory: /bask/homes/f/fspo1218/.cache/pip/wheels/14/f9/07/bb2308587bc2f57158f905a2325f6a89a2befa7437b2d7e137\n",
      "Successfully built lit\n",
      "Installing collected packages: mpmath, lit, cmake, sympy, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 122] Disk quota exceeded\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/bask/apps/live/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import json\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import onnx\n",
    "from typing import Literal\n",
    "from typing_extensions import Literal\n",
    "import matplotlib.pyplot as plt\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "from data2 import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the pytorch model\n",
    "model_py = torch.load(\"./outputs/turing-macro_v01_efficientnetv2-b3_2023-06-27-10-45.pt\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test data\n",
    "test_dataloader = dataloader.build_webdataset_pipeline(\n",
    "        sharedurl=\"./outputs/test-500-{000000..000013}.tar\",\n",
    "        input_size=1000,\n",
    "        batch_size=64,\n",
    "        is_training=False,\n",
    "        num_workers=4,\n",
    "        preprocess_mode=\"tf\",\n",
    "    )\n",
    "print(\"images loaded\")\n",
    "\n",
    "image_dummy, label_dummy = next(iter(test_dataloader))\n",
    "image_batch = image_dummy.to(\"cpu\", non_blocking=True)\n",
    "label_batch = label_dummy.to(\"cpu\", non_blocking=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label_batch[0]\n",
    "image = image_batch[0]\n",
    "print(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label info for the species names\n",
    "f = open(\"./outputs/01_uk_macro_data_numeric_labels.json\")\n",
    "label_info = json.load(f)\n",
    "species_list = label_info[\"species_list\"]\n",
    "print(len(species_list), \" species in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to onnx\n",
    "torch.onnx.export(\n",
    "            model=model_py.eval(),\n",
    "            args=image.unsqueeze(0),\n",
    "            f=\"./outputs/onnx_file.onnx\",\n",
    "            verbose=False,\n",
    "            export_params=True,\n",
    "            do_constant_folding=False,\n",
    "            input_names=['input'],\n",
    "            opset_version=12,\n",
    "            output_names=['output']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tf\n",
    "onnx_model = onnx.load(\"./outputs/onnx_file.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "tf_rep = prepare(onnx_model, device='CPU')\n",
    "tf_rep.export_graph(\"./outputs/tf_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a working tensorflow model. Lets test one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(image_index, ax):\n",
    "    image = image_batch[image_index]\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    label = label_batch[image_index]\n",
    "\n",
    "    output = tf_rep.run(image)\n",
    "\n",
    "    true_str = \"True: \" + species_list[int(label)]\n",
    "    pred_str = \"Pred: \" + species_list[np.argmax(output)]\n",
    "    text = \"Image \" + str(image_index)\n",
    "\n",
    "    ax.imshow(image_batch[image_index].permute(1, 2, 0))\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, \n",
    "                top=False, left=False, right=False, \n",
    "                labelbottom=False, labelleft=False) \n",
    "\n",
    "    # add annotation label to the plot\n",
    "    ax.annotate(text, (50, 50), color='white')\n",
    "    ax.annotate(true_str, (50, 850), color='white')\n",
    "    ax.annotate(pred_str, (50, 900), color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib subplots 3x3\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "plot_predictions(10, axs[0, 0])\n",
    "plot_predictions(11, axs[0, 1])\n",
    "plot_predictions(12, axs[0, 2])\n",
    "plot_predictions(13, axs[1, 0])\n",
    "plot_predictions(14, axs[1, 1])\n",
    "plot_predictions(15, axs[1, 2])\n",
    "plot_predictions(16, axs[2, 0])\n",
    "plot_predictions(17, axs[2, 1])\n",
    "plot_predictions(18, axs[2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets convert this to s TF Lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tfLite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./outputs/tf_file\")\n",
    "converter.experimental_new_converter = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.allow_custom_ops=True\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./outputs/compressed_model.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing \n",
    "\n",
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"gbif\",\n",
    "    entity=\"kg-test\", \n",
    "    tags=\"tflite\"\n",
    ")\n",
    "\n",
    "wandb.init(settings=wandb.Settings(start_method=\"fork\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.lite.Interpreter(model_path=\"./outputs/compressed_model.tflite\")\n",
    "model.allocate_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the species label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"./outputs/compressed_model.tflite\")\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "print(\"tflite model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['True_label', 'Pytorch_prediction', 'TF_prediction', 'TFLite_prediction']\n",
    "\n",
    "f = open('myfile.csv', 'w', newline=\"\")\n",
    "\n",
    "# create the csv writer\n",
    "writer = csv.writer(f, delimiter=';')\n",
    "writer.writerow(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚨🚨 warning: the next cell will take a while to run 🚨🚨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in test_dataloader:\n",
    "\n",
    "\n",
    "    image_batch, label_batch = image_batch.to(\n",
    "        device, non_blocking=True\n",
    "    ), label_batch.to(device, non_blocking=True)\n",
    "    \n",
    "    for i in range(len(image_batch)):\n",
    "        s_time = time.time()\n",
    "        image = image_batch[i]\n",
    "\n",
    "\n",
    "        # For pytorch model\n",
    "        outputs_py = model_py(image.unsqueeze(0))\n",
    "        prediction_py = int(torch.max(outputs_py.data, 1)[1].numpy())\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], image.unsqueeze(0))\n",
    "        interpreter.invoke()\n",
    "        outputs_tf = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        prediction_tf = np.squeeze(outputs_tf)\n",
    "        prediction_tf = int(prediction_tf.argsort()[-1:][::-1])\n",
    "        \n",
    "        true_label = int(label_batch[i].numpy())\n",
    "        print(\"true: \", true_label, species_list[true_label], \", \"\n",
    "            \", py: \", prediction_py, species_list[prediction_py], \", \"\n",
    "            \", tf: \", prediction_tf, species_list[prediction_tf])\n",
    "        line = [str(int(true_label)), str(prediction_py), str(prediction_tf)]\n",
    "        writer.writerow(line)\n",
    "        \n",
    "        wandb.log(\n",
    "            {\"training loss\": 0, \"validation loss\": 0, \"epoch\": i}\n",
    "        )\n",
    "        \n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train_micro_species_top1\": 100,\n",
    "                \"train_micro_genus_top1\": 100,\n",
    "                \"train_micro_family_top1\": 100,\n",
    "                \"val_micro_species_top1\": 100,\n",
    "                \"val_micro_genus_top1\": 100,\n",
    "                \"val_micro_family_top1\": 100,\n",
    "                \"epoch\": i,\n",
    "            }\n",
    "        )\n",
    "        e_time = (time.time() - s_time) / 60  # time taken in minutes\n",
    "        wandb.log({\"time per epoch\": e_time, \"epoch\": i})\n",
    "\n",
    "wandb.log_artifact(\"~/Desktop/wandblog\", name=mod_name, type=\"models\")\n",
    "\n",
    "wandb.log({\"final micro accuracy\": 100})\n",
    "wandb.log({\"final macro accuracy\": 100})\n",
    "wandb.log({\"configuration\": \"\"})\n",
    "wandb.log({\"tax accuracy\": 100})\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
