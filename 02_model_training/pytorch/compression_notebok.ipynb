{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "species_classifier kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the time of writing baskerville is down so recreating venv\n",
    "! pip install attrs==23.1.0\n",
    "! pip install braceexpand==0.1.7\n",
    "! pip install cattrs==23.1.1\n",
    "! pip install docker_pycreds==0.4.0\n",
    "! pip install exceptiongroup==1.1.1\n",
    "! pip install geojson_rewind==1.0.3\n",
    "! pip install geomet==1.0.0\n",
    "! pip install gitdb==4.0.10\n",
    "! pip install GitPython==3.1.31\n",
    "! pip install huggingface_hub==0.15.1\n",
    "! pip install joblib==1.2.0\n",
    "! pip install keras==2.12.0\n",
    "! pip install matplotlib==3.6.3\n",
    "! pip install numpy==1.19.5\n",
    "! pip install packaging==23.1\n",
    "! pip install pandas==1.4.4\n",
    "! pip install pathtools==0.1.2\n",
    "! pip install pip==23.1.2\n",
    "! pip install pygbif==0.6.3\n",
    "! pip install requests_cache==1.0.1\n",
    "! pip install safetensors==0.3.1\n",
    "! pip install scikit_learn==1.2.2\n",
    "! pip install sentry_sdk==1.9.0\n",
    "! pip install setproctitle==1.3.2\n",
    "! pip install setuptools==49.2.1\n",
    "! pip install smmap==5.0.0\n",
    "! pip install timm==0.9.2\n",
    "! pip install torchsummary==1.5.1\n",
    "! pip install typeguard==3.0.0\n",
    "! pip install typing_extensions==4.7.1\n",
    "! pip install url_normalize==1.4.3\n",
    "! pip install wandb==0.15.4\n",
    "! pip install webdataset==0.2.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import json\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import onnx\n",
    "from typing import Literal\n",
    "from typing_extensions import Literal\n",
    "import matplotlib.pyplot as plt\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "from data2 import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the pytorch model\n",
    "model_py = torch.load(\"./outputs/turing-macro_v01_efficientnetv2-b3_2023-06-27-10-45.pt\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_batch = label_dummy.to(\"cpu\", non_blocking=True)\n",
    "label = label_batch[0]\n",
    "print(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test data\n",
    "test_dataloader = dataloader.build_webdataset_pipeline(\n",
    "        sharedurl=\"./outputs/test-500-{000000..000013}.tar\",\n",
    "        input_size=1000,\n",
    "        batch_size=64,\n",
    "        is_training=False,\n",
    "        num_workers=4,\n",
    "        preprocess_mode=\"tf\",\n",
    "    )\n",
    "print(\"images loaded\")\n",
    "\n",
    "image_dummy, label_dummy = next(iter(test_dataloader))\n",
    "image_batch = image_dummy.to(\"cpu\", non_blocking=True)\n",
    "label_batch = label_dummy.to(\"cpu\", non_blocking=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label info for the species names\n",
    "f = open(\"./outputs/01_uk_macro_data_numeric_labels.json\")\n",
    "label_info = json.load(f)\n",
    "species_list = label_info[\"species_list\"]\n",
    "print(len(species_list), \" species in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to onnx\n",
    "torch.onnx.export(\n",
    "            model=model_py.eval(),\n",
    "            args=image,\n",
    "            f=\"./outputs/onnx_file.onnx\",\n",
    "            verbose=False,\n",
    "            export_params=True,\n",
    "            do_constant_folding=False,\n",
    "            input_names=['input'],\n",
    "            opset_version=12,\n",
    "            output_names=['output']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tf\n",
    "onnx_model = onnx.load(\"./outputs/onnx_file.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "tf_rep = prepare(onnx_model, device='CPU')\n",
    "tf_rep.export_graph(\"./outputs/tf_file\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a working tensorflow model. Lets test one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(image_index, ax):\n",
    "    image = image_batch[image_index]\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    label = label_batch[image_index]\n",
    "\n",
    "    output = tf_rep.run(image)\n",
    "\n",
    "    true_str = \"True: \" + species_list[int(label)]\n",
    "    pred_str = \"Pred: \" + species_list[np.argmax(output)]\n",
    "    text = \"Image \" + str(image_index)\n",
    "\n",
    "    ax.imshow(image_batch[image_index].permute(1, 2, 0))\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, \n",
    "                top=False, left=False, right=False, \n",
    "                labelbottom=False, labelleft=False) \n",
    "\n",
    "    # add annotation label to the plot\n",
    "    ax.annotate(text, (50, 50), color='white')\n",
    "    ax.annotate(true_str, (50, 850), color='white')\n",
    "    ax.annotate(pred_str, (50, 900), color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib subplots 3x3\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "plot_predictions(10, axs[0, 0])\n",
    "plot_predictions(11, axs[0, 1])\n",
    "plot_predictions(12, axs[0, 2])\n",
    "plot_predictions(13, axs[1, 0])\n",
    "plot_predictions(14, axs[1, 1])\n",
    "plot_predictions(15, axs[1, 2])\n",
    "plot_predictions(16, axs[2, 0])\n",
    "plot_predictions(17, axs[2, 1])\n",
    "plot_predictions(18, axs[2, 2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets convert this to s TF Lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tfLite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./outputs/tf_file\")\n",
    "converter.experimental_new_converter = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.allow_custom_ops=True\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./outputs/compressed_model.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing \n",
    "\n",
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.lite.Interpreter(model_path=\"./outputs/compressed_model.tflite\")\n",
    "model.allocate_tensors()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the species label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"./outputs/compressed_model.tflite\")\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "print(\"tflite model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['True_label', 'Pytorch_prediction', 'TF_prediction', 'TFLite_prediction']\n",
    "\n",
    "f = open('myfile.csv', 'w', newline=\"\")\n",
    "\n",
    "# create the csv writer\n",
    "writer = csv.writer(f, delimiter=';')\n",
    "writer.writerow(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in test_dataloader:\n",
    "\n",
    "\n",
    "    image_batch, label_batch = image_batch.to(\n",
    "        device, non_blocking=True\n",
    "    ), label_batch.to(device, non_blocking=True)\n",
    "    \n",
    "    for i in range(len(image_batch)):\n",
    "        image = image_batch[i]\n",
    "\n",
    "\n",
    "        # For pytorch model\n",
    "        outputs_py = model_py(image.unsqueeze(0))\n",
    "        prediction_py = int(torch.max(outputs_py.data, 1)[1].numpy())\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], image.unsqueeze(0))\n",
    "        interpreter.invoke()\n",
    "        outputs_tf = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        prediction_tf = np.squeeze(outputs_tf)\n",
    "        prediction_tf = int(prediction_tf.argsort()[-1:][::-1])\n",
    "        \n",
    "        true_label = int(label_batch[i].numpy())\n",
    "        print(\"true: \", true_label, species_list[true_label], \", \"\n",
    "            \", py: \", prediction_py, species_list[prediction_py], \", \"\n",
    "            \", tf: \", prediction_tf, species_list[prediction_tf])\n",
    "        line = [str(int(true_label)), str(prediction_py), str(prediction_tf)]\n",
    "        writer.writerow(line)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
